# `TensorRT_jll.jl` (v8.0.3+0)

[![deps](https://juliahub.com/docs/TensorRT_jll/deps.svg)](https://juliahub.com/ui/Packages/TensorRT_jll/Q0mZz?page=2)

This is an autogenerated package constructed using [`BinaryBuilder.jl`](https://github.com/JuliaPackaging/BinaryBuilder.jl).

The originating [`build_tarballs.jl`](https://github.com/JuliaPackaging/Yggdrasil/blob/58345e099a5afe0ca5f960619b08f8d80e6dc287/T/TensorRT/build_tarballs.jl) script can be found on [`Yggdrasil`](https://github.com/JuliaPackaging/Yggdrasil/), the community build tree.")

## Bug Reports

If you have any issue, please report it to the Yggdrasil [bug tracker](https://github.com/JuliaPackaging/Yggdrasil/issues).

## Documentation

For more details about JLL packages and how to use them, see `BinaryBuilder.jl` [documentation](https://docs.binarybuilder.org/stable/jll/).

## Sources

The tarballs for `TensorRT_jll.jl` have been built from these sources:

* compressed archive: https://developer.nvidia.com/compute/machine-learning/tensorrt/secure/8.0.3/zip/TensorRT-8.0.3.4.Windows10.x86_64.cuda-11.3.cudnn8.2.zip (SHA256 checksum: `a347d6e7981d0497ba60c5de78716101d73105946e1ff745f0f426f51ea691b0`)

## Platforms

`TensorRT_jll.jl` is available for the following platforms:

* `Windows x86_64 {cuda=11.3}` (`x86_64-w64-mingw32-cuda+11.3`)

## Dependencies

The following JLL packages are required by `TensorRT_jll.jl`:

* [`CUDNN_jll`](https://github.com/JuliaBinaryWrappers/CUDNN_jll.jl)

## Products

The code bindings within this package are autogenerated from the following `Products`:

* `LibraryProduct`: `libnvinfer`
* `LibraryProduct`: `libnvinfer_plugin`
* `LibraryProduct`: `libnvonnxparser`
* `LibraryProduct`: `libnvparsers`
* `ExecutableProduct`: `trtexec`
